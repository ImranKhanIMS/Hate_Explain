{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7EGDu9Wbvnm2",
      "metadata": {
        "id": "7EGDu9Wbvnm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb18008c-e6b6-4f13-e672-448c329fc800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'Hate_Explain'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 109 (delta 37), reused 104 (delta 32), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (109/109), 2.36 MiB | 5.93 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "/content/Hate_Explain\n",
            "DONE\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# GOOGLE COLAB SETUP - Mount Drive & Extract Data\n",
        "# ================================================\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/ImranKhanIMS/Hate_Explain.git\n",
        "%cd Hate_Explain\n",
        "print(\"DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a557a518",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a557a518",
        "outputId": "95beaf86-ed25-4c2a-fb2c-bcad35eb769d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting copy\n",
            "cp: cannot stat '/content/drive/MyDrive/glove.42B.300d.zip': No such file or directory\n",
            "Starting extraction\n",
            "unzip:  cannot find or open ./Data/glove.42B.300d.zip, ./Data/glove.42B.300d.zip.zip or ./Data/glove.42B.300d.zip.ZIP.\n",
            "Done extraction\n",
            "\n",
            "GPU Available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# LOAD THE SMALL DATASET (GIVES KEY ERRORS SINCE IT DOESNT HAVE THE MOST OF THE WORDS)\n",
        "# !cp /content/drive/MyDrive/glove.42B.300d.small.zip ./Data/\n",
        "# Extract the zip file\n",
        "# !unzip -q ./Data/glove.42B.300d.small.zip -d ./Data/\n",
        "# !mv ./Data/glove.42B.300d.small.txt  ./Data/glove.42B.300d.txt\n",
        "\n",
        "# LOAD THE FULL DATASET\n",
        "print(\"Starting copy\")\n",
        "!cp /content/drive/MyDrive/glove.42B.300d.zip ./Data/\n",
        "# Extract the zip file\n",
        "print(\"Starting extraction\")\n",
        "!unzip -q ./Data/glove.42B.300d.zip -d ./Data/\n",
        "print(\"Done extraction\")\n",
        "\n",
        "# Clean up zip file (if needed)\n",
        "# !rm ./Data/glove.42B.300d.small.zip\n",
        "# !rm ./Data/glove.42B.300d.zip\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b64eb58",
      "metadata": {
        "id": "7b64eb58"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c630f3f1",
      "metadata": {
        "id": "c630f3f1"
      },
      "outputs": [],
      "source": [
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ed11d7bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed11d7bc",
        "outputId": "4da37de0-0601-4e1f-a8c4-05b17ee5ae1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create necessary directories\n",
        "import os\n",
        "os.makedirs('Saved', exist_ok=True)\n",
        "os.makedirs('explanations_dicts', exist_ok=True)\n",
        "print(\"Directories created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e725d768",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e725d768",
        "outputId": "d51f72f2-91aa-4232-95a2-f4c5da2a32b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.57.6)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: spacy>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.8.11)\n",
            "Collecting gensim>=4.3.0 (from -r requirements.txt (line 11))\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting ekphrasis>=0.5.4 (from -r requirements.txt (line 12))\n",
            "  Downloading ekphrasis-0.5.4-py3-none-any.whl.metadata (610 bytes)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Collecting lime>=0.2.0.1 (from -r requirements.txt (line 19))\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting GPUtil>=1.4.0 (from -r requirements.txt (line 20))\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (10.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r requirements.txt (line 6)) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (0.21.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.12.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim>=4.3.0->-r requirements.txt (line 11)) (7.5.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (3.3.0)\n",
            "Collecting colorama (from ekphrasis>=0.5.4->-r requirements.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ujson (from ekphrasis>=0.5.4->-r requirements.txt (line 12))\n",
            "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (3.9.1)\n",
            "Collecting ftfy (from ekphrasis>=0.5.4->-r requirements.txt (line 12))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (3.3.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime>=0.2.0.1->-r requirements.txt (line 19)) (0.25.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (2026.1.4)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->-r requirements.txt (line 19)) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->-r requirements.txt (line 19)) (2026.1.14)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->-r requirements.txt (line 19)) (0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim>=4.3.0->-r requirements.txt (line 11)) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.7.0->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.7.0->-r requirements.txt (line 10)) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10)) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.7.0->-r requirements.txt (line 10)) (0.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->ekphrasis>=0.5.4->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 2)) (3.0.3)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lime, GPUtil\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=3ebb12defa425f956db80961dfc4dd0c98707c3bbb0d6ad07f44074283f23f1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=7c42fb5ba9ebcf8109b68cd4e8e0f21e8923b5ddfcc84385b95d82eb7a83861f\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a8/b7/d8a067c31a74de9ca252bbe53dea5f896faabd25d55f541037\n",
            "Successfully built lime GPUtil\n",
            "Installing collected packages: GPUtil, ujson, ftfy, colorama, gensim, lime, ekphrasis\n",
            "Successfully installed GPUtil-1.4.0 colorama-0.4.6 ekphrasis-0.5.4 ftfy-6.3.1 gensim-4.4.0 lime-0.2.0.1 ujson-5.11.0\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Install required packages (run this if not already installed)\n",
        "!pip install -r requirements.txt\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "931f2403",
      "metadata": {
        "id": "931f2403"
      },
      "source": [
        "## 2. Download and Prepare GloVe Embeddings\n",
        "\n",
        "**Note:** This step is only required once. Skip if you already have the file. Like i did with in the google drive mounted. If not it downloads it right here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca9c64cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca9c64cf",
        "outputId": "76d688e2-b87d-48de-b0a2-fdddf7f3b85b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-01 17:38:02--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2026-02-01 17:38:03--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2026-02-01 17:38:03--  https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘Data/glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  3.42MB/s    in 8m 58s  \n",
            "\n",
            "2026-02-01 17:47:01 (3.33 MB/s) - ‘Data/glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n",
            "Archive:  Data/glove.42B.300d.zip\n",
            "  inflating: Data/glove.42B.300d.txt  \n",
            "GloVe embeddings downloaded!\n"
          ]
        }
      ],
      "source": [
        "# Download GloVe embeddings (only run if needed)\n",
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip -P Data/\n",
        "!unzip Data/glove.42B.300d.zip -d Data/\n",
        "!rm Data/glove.42B.300d.zip\n",
        "print(\"GloVe embeddings downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "044d03bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "044d03bc",
        "outputId": "15612565-d138-4f6c-bcb6-cf4b4eeb1148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting GloVe to Word2Vec format...\n",
            "Loading and saving model (this may take a few minutes)...\n",
            "Done! word2vec.model saved.\n"
          ]
        }
      ],
      "source": [
        "# Convert GloVe to Word2Vec format (REQUIRED for Colab - run this!)\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "# Convert GloVe format to Word2Vec format\n",
        "print(\"Converting GloVe to Word2Vec format...\")\n",
        "glove2word2vec('Data/glove.42B.300d.txt', 'Data/glove.42B.300d_w2v.txt')\n",
        "\n",
        "# Load and save in gensim format\n",
        "print(\"Loading and saving model (this may take a few minutes)...\")\n",
        "word2vecmodel1 = KeyedVectors.load_word2vec_format('Data/glove.42B.300d_w2v.txt', binary=False)\n",
        "word2vecmodel1.save(\"Data/word2vec.model\")\n",
        "\n",
        "# Clean up intermediate files\n",
        "import gc\n",
        "del word2vecmodel1\n",
        "gc.collect()\n",
        "\n",
        "# Remove large text files to save space\n",
        "import os\n",
        "os.remove('Data/glove.42B.300d.txt')\n",
        "os.remove('Data/glove.42B.300d_w2v.txt')\n",
        "print(\"Done! word2vec.model saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7938582a",
      "metadata": {
        "id": "7938582a"
      },
      "source": [
        "## 3. Import Dependencies and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7ff1eed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff1eed7",
        "outputId": "9e766609-7870-4130-e92b-83b6a3d74a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading twitter - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
            "Reading twitter - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n",
            "Reading english - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/english/counts_1grams.txt\n"
          ]
        }
      ],
      "source": [
        "# Import the training module\n",
        "from manual_training_inference import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e9079f11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9079f11",
        "outputId": "67ccf20f-580f-458c-9dbc-cf7dc351463c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Load model parameters from JSON configuration\n",
        "import json\n",
        "import ast\n",
        "import torch\n",
        "\n",
        "path_file = 'best_model_json/bestModel_birnnscrat.json'\n",
        "with open(path_file, mode='r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "# Convert string values to appropriate types\n",
        "for key in params:\n",
        "    if params[key] == 'True':\n",
        "        params[key] = True\n",
        "    elif params[key] == 'False':\n",
        "        params[key] = False\n",
        "    if key in ['batch_size', 'num_classes', 'hidden_size', 'supervised_layer_pos',\n",
        "               'num_supervised_heads', 'random_seed', 'max_length']:\n",
        "        if params[key] != 'N/A':\n",
        "            params[key] = int(params[key])\n",
        "    if (key == 'weights') and (params['auto_weights'] == False):\n",
        "        params[key] = ast.literal_eval(params[key])\n",
        "\n",
        "# Configure for Colab execution\n",
        "params['logging'] = 'local'\n",
        "params['device'] = 'cuda'  # Use GPU in Colab\n",
        "params['best_params'] = False\n",
        "\n",
        "# Setup device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('WARNING: GPU not available. Using CPU (training will be slow).')\n",
        "    print('Go to Runtime → Change runtime type → GPU')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "01d7f249",
      "metadata": {
        "id": "01d7f249"
      },
      "outputs": [],
      "source": [
        "# Data folder configuration\n",
        "dict_data_folder = {\n",
        "    '2': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes_two.npy'},\n",
        "    '3': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "# Configure training parameters\n",
        "params['variance'] = 1\n",
        "params['epochs'] = 5  # Reduce for faster testing\n",
        "params['to_save'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0d1e4a47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d1e4a47",
        "outputId": "d9d546dd-8867-4d60-e1eb-7a873276b15b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 2-class model...\n",
            "total_data 20148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20148/20148 [00:27<00:00, 727.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_error: 0\n",
            "no_majority: 919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 2772/15383 [00:00<00:01, 12472.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:01<00:00, 13729.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22236, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:00<00:00, 21076.24it/s]\n",
            "100%|██████████| 1922/1922 [00:00<00:00, 12742.24it/s]\n",
            "100%|██████████| 1924/1924 [00:00<00:00, 13113.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dataset size: 19229\n",
            "[1.2301791 0.8423818]\n",
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:13, 36.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.3096098394255\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 553.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.62\n",
            " Fscore: 0.61\n",
            " Precision: 0.73\n",
            " Recall: 0.67\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 481.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.59\n",
            " Precision: 0.72\n",
            " Recall: 0.66\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 603.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.61\n",
            " Fscore: 0.59\n",
            " Precision: 0.72\n",
            " Recall: 0.66\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5936, accuracy: 0.6065\n",
            "  Val  - fscore: 0.5853, accuracy: 0.5994\n",
            "  Train- fscore: 0.6097, accuracy: 0.6204\n",
            "0.585307870951544 0\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.1856427103467\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 558.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.71\n",
            " Fscore: 0.70\n",
            " Precision: 0.76\n",
            " Recall: 0.74\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 581.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.65\n",
            " Precision: 0.72\n",
            " Recall: 0.70\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 384.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.67\n",
            " Fscore: 0.66\n",
            " Precision: 0.74\n",
            " Recall: 0.71\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6637, accuracy: 0.6668\n",
            "  Val  - fscore: 0.6500, accuracy: 0.6535\n",
            "  Train- fscore: 0.7039, accuracy: 0.7053\n",
            "0.6499931642066925 0.585307870951544\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 40.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.10106578041757\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 537.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.79\n",
            " Fscore: 0.79\n",
            " Precision: 0.80\n",
            " Recall: 0.81\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 373.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.70\n",
            " Fscore: 0.70\n",
            " Precision: 0.73\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 453.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.72\n",
            " Fscore: 0.72\n",
            " Precision: 0.75\n",
            " Recall: 0.75\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.7245, accuracy: 0.7245\n",
            "  Val  - fscore: 0.7029, accuracy: 0.7029\n",
            "  Train- fscore: 0.7904, accuracy: 0.7907\n",
            "0.7029129078321366 0.6499931642066925\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.03212155919067\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:01, 402.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.80\n",
            " Fscore: 0.80\n",
            " Precision: 0.82\n",
            " Recall: 0.83\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:02\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 403.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.68\n",
            " Fscore: 0.68\n",
            " Precision: 0.72\n",
            " Recall: 0.71\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 446.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.67\n",
            " Fscore: 0.67\n",
            " Precision: 0.71\n",
            " Recall: 0.71\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6743, accuracy: 0.6746\n",
            "  Val  - fscore: 0.6781, accuracy: 0.6785\n",
            "  Train- fscore: 0.8038, accuracy: 0.8039\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 294.9913687279715\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:01, 477.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.67\n",
            " Fscore: 0.66\n",
            " Precision: 0.77\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 463.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.58\n",
            " Fscore: 0.57\n",
            " Precision: 0.70\n",
            " Recall: 0.64\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 399.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.59\n",
            " Fscore: 0.57\n",
            " Precision: 0.71\n",
            " Recall: 0.64\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5690, accuracy: 0.5852\n",
            "  Val  - fscore: 0.5695, accuracy: 0.5848\n",
            "  Train- fscore: 0.6642, accuracy: 0.6703\n",
            "best_val_fscore 0.7029129078321366\n",
            "best_test_fscore 0.7244893548038474\n",
            "best_val_rocauc 0\n",
            "best_test_rocauc 0\n",
            "best_val_precision 0.7278937717441984\n",
            "best_test_precision 0.7461769288475966\n",
            "best_val_recall 0.7281676674660345\n",
            "best_test_recall 0.748399854878371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Train with 2 classes (toxic vs non-toxic)\n",
        "params['num_classes'] = 2\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "if params['num_classes'] == 2 and params['auto_weights'] == False:\n",
        "    params['weights'] = [1.0, 1.0]\n",
        "\n",
        "print(f\"Training {params['num_classes']}-class model...\")\n",
        "train_model(params, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cf0fc73b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf0fc73b",
        "outputId": "f400b57a-558c-47e2-af3b-50c3c8a7f141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 3-class model...\n",
            "total_data 20148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20148/20148 [00:28<00:00, 715.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_error: 0\n",
            "no_majority: 919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 1476/15383 [00:00<00:01, 7437.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:01<00:00, 8307.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22236, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:01<00:00, 13694.80it/s]\n",
            "100%|██████████| 1922/1922 [00:00<00:00, 15851.90it/s]\n",
            "100%|██████████| 1924/1924 [00:00<00:00, 20254.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dataset size: 19229\n",
            "[1.0796857 0.8201194 1.1703163]\n",
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 40.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.68468743401604\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 540.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.61\n",
            " Fscore: 0.58\n",
            " Precision: 0.63\n",
            " Recall: 0.58\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 566.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.56\n",
            " Precision: 0.63\n",
            " Recall: 0.56\n",
            " Roc Auc: 0.77\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 599.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.59\n",
            " Fscore: 0.55\n",
            " Precision: 0.62\n",
            " Recall: 0.55\n",
            " Roc Auc: 0.77\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5524, accuracy: 0.5878\n",
            "  Val  - fscore: 0.5617, accuracy: 0.5963\n",
            "  Train- fscore: 0.5782, accuracy: 0.6105\n",
            "0.5616702167867701 0\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 40.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.5435634938198\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:01, 444.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.67\n",
            " Precision: 0.69\n",
            " Recall: 0.67\n",
            " Roc Auc: 0.84\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 552.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.62\n",
            " Fscore: 0.60\n",
            " Precision: 0.62\n",
            " Recall: 0.60\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 492.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.61\n",
            " Precision: 0.64\n",
            " Recall: 0.61\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6150, accuracy: 0.6362\n",
            "  Val  - fscore: 0.5992, accuracy: 0.6223\n",
            "  Train- fscore: 0.6704, accuracy: 0.6873\n",
            "0.5992262854884399 0.5616702167867701\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 40.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.4403857193469\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 552.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.74\n",
            " Fscore: 0.73\n",
            " Precision: 0.74\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.89\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 574.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.63\n",
            " Precision: 0.65\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 580.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.63\n",
            " Precision: 0.65\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6304, accuracy: 0.6492\n",
            "  Val  - fscore: 0.6292, accuracy: 0.6483\n",
            "  Train- fscore: 0.7318, accuracy: 0.7435\n",
            "0.6292216536100552 0.5992262854884399\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:12, 39.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.37425653850215\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 507.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.78\n",
            " Fscore: 0.78\n",
            " Precision: 0.78\n",
            " Recall: 0.77\n",
            " Roc Auc: 0.92\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 497.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.64\n",
            " Precision: 0.65\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 477.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.63\n",
            " Precision: 0.64\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.80\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6332, accuracy: 0.6435\n",
            "  Val  - fscore: 0.6400, accuracy: 0.6504\n",
            "  Train- fscore: 0.7758, accuracy: 0.7817\n",
            "0.639963820145986 0.6292216536100552\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:12, 37.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.3143782585921\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:01, 455.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.76\n",
            " Fscore: 0.75\n",
            " Precision: 0.78\n",
            " Recall: 0.74\n",
            " Roc Auc: 0.92\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 396.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.57\n",
            " Precision: 0.62\n",
            " Recall: 0.57\n",
            " Roc Auc: 0.77\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 356.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.57\n",
            " Precision: 0.62\n",
            " Recall: 0.56\n",
            " Roc Auc: 0.76\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5673, accuracy: 0.5951\n",
            "  Val  - fscore: 0.5701, accuracy: 0.5968\n",
            "  Train- fscore: 0.7524, accuracy: 0.7645\n",
            "best_val_fscore 0.639963820145986\n",
            "best_test_fscore 0.6332487108352621\n",
            "best_val_rocauc 0.8071006833165059\n",
            "best_test_rocauc 0.8039198584224749\n",
            "best_val_precision 0.6517608919125689\n",
            "best_test_precision 0.6419289825978067\n",
            "best_val_recall 0.6348165172902596\n",
            "best_test_recall 0.6290887648657669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Train with 3 classes (hatespeech, offensive, normal)\n",
        "params['num_classes'] = 3\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "if params['num_classes'] == 2 and params['auto_weights'] == False:\n",
        "    params['weights'] = [1.0, 1.0]\n",
        "\n",
        "print(f\"Training {params['num_classes']}-class model...\")\n",
        "train_model(params, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d53f6556",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d53f6556",
        "outputId": "a4095c6e-8926-4e8a-fc10-765e98a7ab17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Clean up memory\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6620763",
      "metadata": {
        "id": "a6620763"
      },
      "source": [
        "## 4. Testing and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7119f203",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7119f203",
        "outputId": "b3216974-751b-4647-b1b4-6436bd2aa980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-01 18:22:55.113784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769970175.156004   12275 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769970175.168000   12275 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769970175.208250   12275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970175.208296   12275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970175.208305   12275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970175.208312   12275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n",
            "total_data 1142\n",
            "100% 1142/1142 [00:01<00:00, 707.52it/s]\n",
            "100% 1142/1142 [00:00<00:00, 19866.10it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:00<00:00, 83.26it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " Accuracy: 0.578\n",
            " Fscore: 0.442\n",
            " Precision: 0.525\n",
            " Recall: 0.383\n",
            " Test took: 0:00:00\n",
            "100% 1142/1142 [00:00<00:00, 6735.36it/s]\n",
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n",
            "100% 1142/1142 [00:00<00:00, 15954.99it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:00<00:00, 400.00it/s]\n",
            "100% 1142/1142 [00:00<00:00, 9562.41it/s]\n",
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n",
            "100% 1142/1142 [00:00<00:00, 13049.96it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:00<00:00, 422.00it/s]\n",
            "\u001b[0m2026-02-01 18:24:08.834806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769970248.862089   12621 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769970248.870751   12621 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769970248.900554   12621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970248.900594   12621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970248.900600   12621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970248.900604   12621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Hate_Explain/testing_for_bias.py\", line 282, in <module>\n",
            "    final_dict=get_final_dict(params, params['data_file'],topk=5)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Hate_Explain/testing_for_bias.py\", line 214, in get_final_dict\n",
            "    list_dict_org,test_data=standaloneEval(params, extra_data_path=test_data, topk=2)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Hate_Explain/testing_for_bias.py\", line 110, in standaloneEval\n",
            "    params['weights']=class_weight.compute_class_weight('balanced',np.unique(y_test),y_test).astype('float32')\n",
            "                      ^^^^^^^^^^^^\n",
            "NameError: name 'class_weight' is not defined\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Run testing scripts\n",
        "!python testing_with_rational.py birnn_scrat 100\n",
        "!python testing_for_bias.py birnn_scrat 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9fb37bfd",
      "metadata": {
        "id": "9fb37bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a59b32a-487d-40dc-d699-08f759772eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bestModel_birnnscrat_100_explanation_top5.json\n"
          ]
        }
      ],
      "source": [
        "# Check generated explanation files\n",
        "!ls explanations_dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e805472e",
      "metadata": {
        "id": "e805472e"
      },
      "source": [
        "---\n",
        "\n",
        "# Bias Calculation\n",
        "\n",
        "Based on: Borkan et al. (2019) - \"Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cd70e916",
      "metadata": {
        "id": "cd70e916"
      },
      "outputs": [],
      "source": [
        "# Import required libraries for bias calculation\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ae89aa08",
      "metadata": {
        "id": "ae89aa08"
      },
      "outputs": [],
      "source": [
        "# Import data collection utilities\n",
        "from Preprocess.dataCollect import get_annotated_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7b7497b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b7497b6",
        "outputId": "8e9e2e79-d285-45af-c65e-4327bf8539f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 20148 samples\n"
          ]
        }
      ],
      "source": [
        "# Configure data loading for 2-class (toxic/non-toxic)\n",
        "dict_data_folder = {\n",
        "    '2': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes_two.npy'},\n",
        "    '3': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "params = {}\n",
        "params['num_classes'] = 2  # toxic vs non-toxic\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "# Load the annotated dataset\n",
        "data_all_labelled = get_annotated_data(params)\n",
        "print(f\"Loaded {len(data_all_labelled)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c9ddf105",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "c9ddf105",
        "outputId": "64d9512e-88a7-4c73-d69a-874b06ad20eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       post_id  \\\n",
              "0  1179055004553900032_twitter   \n",
              "1  1179063826874032128_twitter   \n",
              "2  1178793830532956161_twitter   \n",
              "3  1179088797964763136_twitter   \n",
              "4  1179085312976445440_twitter   \n",
              "\n",
              "                                                text  annotatorid1  \\\n",
              "0  [i, dont, think, im, getting, my, baby, them, ...             1   \n",
              "1  [we, cannot, continue, calling, ourselves, fem...             1   \n",
              "2                [nawt, yall, niggers, ignoring, me]             4   \n",
              "3  [<user>, i, am, bit, confused, coz, chinese, p...             1   \n",
              "4  [this, bitch, in, whataburger, eating, a, burg...             4   \n",
              "\n",
              "              target1      label1  annotatorid2             target2  \\\n",
              "0              [None]      normal             2              [None]   \n",
              "1              [None]      normal             2              [None]   \n",
              "2           [African]      normal             2              [None]   \n",
              "3             [Asian]  hatespeech             4             [Asian]   \n",
              "4  [Caucasian, Women]  hatespeech             2  [Women, Caucasian]   \n",
              "\n",
              "       label2  annotatorid3             target3      label3  \\\n",
              "0      normal             3              [None]      normal   \n",
              "1      normal             3              [None]      normal   \n",
              "2      normal             3           [African]  hatespeech   \n",
              "3   offensive             3             [Asian]  hatespeech   \n",
              "4  hatespeech             3  [Women, Caucasian]   offensive   \n",
              "\n",
              "                                          rationales final_label  \n",
              "0                                                 []   non-toxic  \n",
              "1                                                 []   non-toxic  \n",
              "2                                                 []   non-toxic  \n",
              "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic  \n",
              "4  [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-889a85a4-db55-4ca9-b5b1-f8ebe010937d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>text</th>\n",
              "      <th>annotatorid1</th>\n",
              "      <th>target1</th>\n",
              "      <th>label1</th>\n",
              "      <th>annotatorid2</th>\n",
              "      <th>target2</th>\n",
              "      <th>label2</th>\n",
              "      <th>annotatorid3</th>\n",
              "      <th>target3</th>\n",
              "      <th>label3</th>\n",
              "      <th>rationales</th>\n",
              "      <th>final_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1179055004553900032_twitter</td>\n",
              "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1179063826874032128_twitter</td>\n",
              "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1178793830532956161_twitter</td>\n",
              "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
              "      <td>4</td>\n",
              "      <td>[African]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[African]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1179088797964763136_twitter</td>\n",
              "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>4</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>3</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1179085312976445440_twitter</td>\n",
              "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
              "      <td>4</td>\n",
              "      <td>[Caucasian, Women]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>2</td>\n",
              "      <td>[Women, Caucasian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>3</td>\n",
              "      <td>[Women, Caucasian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-889a85a4-db55-4ca9-b5b1-f8ebe010937d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-889a85a4-db55-4ca9-b5b1-f8ebe010937d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-889a85a4-db55-4ca9-b5b1-f8ebe010937d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_all_labelled",
              "summary": "{\n  \"name\": \"data_all_labelled\",\n  \"rows\": 20148,\n  \"fields\": [\n    {\n      \"column\": \"post_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20148,\n        \"samples\": [\n          \"21376810_gab\",\n          \"1080843707643944965_twitter\",\n          \"1178183797461811200_twitter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotatorid1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95,\n        \"min\": 1,\n        \"max\": 251,\n        \"num_unique_values\": 194,\n        \"samples\": [\n          165,\n          41,\n          215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"hatespeech\",\n          \"offensive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotatorid2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 1,\n        \"max\": 253,\n        \"num_unique_values\": 197,\n        \"samples\": [\n          173,\n          140,\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"offensive\",\n          \"hatespeech\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotatorid3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 1,\n        \"max\": 252,\n        \"num_unique_values\": 198,\n        \"samples\": [\n          96,\n          125,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"hatespeech\",\n          \"offensive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rationales\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"non-toxic\",\n          \"toxic\",\n          \"undecided\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Display sample data\n",
        "data_all_labelled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dc0b0a9f",
      "metadata": {
        "id": "dc0b0a9f"
      },
      "outputs": [],
      "source": [
        "def generate_target_information(dataset):\n",
        "    \"\"\"Extract target community based on majority voting among annotators.\"\"\"\n",
        "    final_target_output = defaultdict(list)\n",
        "    all_communities_selected = []\n",
        "\n",
        "    for each in dataset.iterrows():\n",
        "        # Combine all target communities from 3 annotators\n",
        "        all_targets = each[1]['target1'] + each[1]['target2'] + each[1]['target3']\n",
        "        community_dict = dict(Counter(all_targets))\n",
        "\n",
        "        # Select communities mentioned by at least 2 annotators\n",
        "        for key in community_dict:\n",
        "            if community_dict[key] > 1:\n",
        "                final_target_output[each[1]['post_id']].append(key)\n",
        "                all_communities_selected.append(key)\n",
        "\n",
        "        # If no majority, mark as 'None'\n",
        "        if each[1]['post_id'] not in final_target_output:\n",
        "            final_target_output[each[1]['post_id']].append('None')\n",
        "            all_communities_selected.append('None')\n",
        "\n",
        "    return final_target_output, all_communities_selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "810386dc",
      "metadata": {
        "id": "810386dc"
      },
      "outputs": [],
      "source": [
        "# Generate target information\n",
        "target_information, all_communities_selected = generate_target_information(data_all_labelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "589a7c28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "589a7c28",
        "outputId": "adcc4ce1-6a40-44fd-a8b1-f684d9c09ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 communities: ['African', 'Islam', 'Jewish', 'Homosexual', 'Women', 'Refugee', 'Arab', 'Caucasian', 'Asian', 'Hispanic']\n"
          ]
        }
      ],
      "source": [
        "# Get top 10 communities for bias calculation\n",
        "community_count_dict = Counter(all_communities_selected)\n",
        "\n",
        "# Remove 'None' and 'Other' from consideration\n",
        "community_count_dict.pop('None', None)\n",
        "community_count_dict.pop('Other', None)\n",
        "\n",
        "# Select top 10 communities\n",
        "list_selected_community = [community for community, value in community_count_dict.most_common(10)]\n",
        "print(f\"Top 10 communities: {list_selected_community}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "02c85f4a",
      "metadata": {
        "id": "02c85f4a"
      },
      "outputs": [],
      "source": [
        "# Filter target information to only include top 10 communities\n",
        "final_target_information = {}\n",
        "for each in target_information:\n",
        "    temp = list(set(target_information[each]) & set(list_selected_community))\n",
        "    if len(temp) == 0:\n",
        "        final_target_information[each] = None\n",
        "    else:\n",
        "        final_target_information[each] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d537ba3a",
      "metadata": {
        "id": "d537ba3a"
      },
      "outputs": [],
      "source": [
        "# Add target category column to dataset\n",
        "data_all_labelled['final_target_category'] = data_all_labelled['post_id'].map(final_target_information)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7dd8cd32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dd8cd32",
        "outputId": "83365cf7-697f-4cd6-b87f-8b97921e6b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples for bias evaluation: 1924\n"
          ]
        }
      ],
      "source": [
        "# Load test split IDs and filter data\n",
        "with open('./Data/post_id_divisions.json', 'r') as fp:\n",
        "    post_id_dict = json.load(fp)\n",
        "\n",
        "data_all_labelled_bias = data_all_labelled[data_all_labelled['post_id'].isin(post_id_dict['test'])]\n",
        "print(f\"Test samples for bias evaluation: {len(data_all_labelled_bias)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "14ae2de9",
      "metadata": {
        "id": "14ae2de9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Bias score file mapping for the trained model\n",
        "bias_score_file_mapping = {\n",
        "    'BiRNN-Attn': 'bestModel_birnnscrat_bias.json',\n",
        "}\n",
        "\n",
        "parent_path = './explanations_dicts/'\n",
        "method_list = ['subgroup', 'bpsn', 'bnsp']\n",
        "community_list = list(list_selected_community)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "757024c0",
      "metadata": {
        "id": "757024c0"
      },
      "outputs": [],
      "source": [
        "def convert_to_score(label_name, label_dict):\n",
        "    \"\"\"Convert classification to toxicity score [0-1].\"\"\"\n",
        "    if label_name == 'non-toxic':\n",
        "        return 1 - label_dict[label_name]\n",
        "    else:\n",
        "        return label_dict[label_name]\n",
        "\n",
        "\n",
        "def bias_evaluation_metric(dataset, method, community):\n",
        "    \"\"\"Divide IDs into positive/negative based on bias evaluation method.\"\"\"\n",
        "    positive_ids = []\n",
        "    negative_ids = []\n",
        "\n",
        "    for eachrow in dataset.iterrows():\n",
        "        if eachrow[1]['final_target_category'] is None:\n",
        "            continue\n",
        "\n",
        "        is_community = community in eachrow[1]['final_target_category']\n",
        "        is_toxic = eachrow[1]['final_label'] != 'non-toxic'\n",
        "\n",
        "        if method == 'subgroup':\n",
        "            if is_community:\n",
        "                if is_toxic:\n",
        "                    positive_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    negative_ids.append(eachrow[1]['post_id'])\n",
        "        elif method == 'bpsn':\n",
        "            if is_community and not is_toxic:\n",
        "                negative_ids.append(eachrow[1]['post_id'])\n",
        "            elif not is_community and is_toxic:\n",
        "                positive_ids.append(eachrow[1]['post_id'])\n",
        "        elif method == 'bnsp':\n",
        "            if is_community and is_toxic:\n",
        "                positive_ids.append(eachrow[1]['post_id'])\n",
        "            elif not is_community and not is_toxic:\n",
        "                negative_ids.append(eachrow[1]['post_id'])\n",
        "        else:\n",
        "            print('Incorrect method selected!')\n",
        "\n",
        "    return {'positiveID': positive_ids, 'negativeID': negative_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "41dd1847",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6174789e9b6f4abf825aecb7f69ce7cc",
            "8f3c623c36c044e2bc78d4aeb8c06a52",
            "9764470ad7c1406589ba918114b5ee05",
            "8813bce2068342e98a0c7075317c0820",
            "5b5c5bb0ce5c4e06a6b4daad2062c220",
            "19f8e6fc9be04be68fee2ecf4647c5b5",
            "fd49177ebaf2458d94468ec99b5fe6ed",
            "06a334c19ae64d799719e418eb6bd476",
            "ed08a83f376d4f8e81e88caedd306c62",
            "cc2841eed00942589f8f99d610cdfd11",
            "e996e39e10fb4de9a9248b267c3344be"
          ]
        },
        "id": "41dd1847",
        "outputId": "e5051624-f006-452c-b43b-372f40e53c28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing models:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6174789e9b6f4abf825aecb7f69ce7cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ./explanations_dicts/bestModel_birnnscrat_bias.json not found. Run testing scripts first.\n"
          ]
        }
      ],
      "source": [
        "# Calculate bias scores\n",
        "final_bias_dictionary = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "for each_model in tqdm(bias_score_file_mapping, desc=\"Processing models\"):\n",
        "    total_data = {}\n",
        "    filepath = parent_path + bias_score_file_mapping[each_model]\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Warning: {filepath} not found. Run testing scripts first.\")\n",
        "        continue\n",
        "\n",
        "    with open(filepath) as fp:\n",
        "        for line in fp:\n",
        "            data = json.loads(line)\n",
        "            total_data[data['annotation_id']] = data\n",
        "\n",
        "    for each_method in method_list:\n",
        "        for each_community in community_list:\n",
        "            community_data = bias_evaluation_metric(data_all_labelled_bias, each_method, each_community)\n",
        "            truth_values = []\n",
        "            prediction_values = []\n",
        "\n",
        "            label_to_value = {'toxic': 1.0, 'non-toxic': 0.0}\n",
        "\n",
        "            for each in community_data['positiveID']:\n",
        "                if each in total_data:\n",
        "                    truth_values.append(label_to_value[total_data[each]['ground_truth']])\n",
        "                    prediction_values.append(convert_to_score(\n",
        "                        total_data[each]['classification'],\n",
        "                        total_data[each]['classification_scores']\n",
        "                    ))\n",
        "\n",
        "            for each in community_data['negativeID']:\n",
        "                if each in total_data:\n",
        "                    truth_values.append(label_to_value[total_data[each]['ground_truth']])\n",
        "                    prediction_values.append(convert_to_score(\n",
        "                        total_data[each]['classification'],\n",
        "                        total_data[each]['classification_scores']\n",
        "                    ))\n",
        "\n",
        "            if len(truth_values) > 0 and len(set(truth_values)) > 1:\n",
        "                roc_output_value = roc_auc_score(truth_values, prediction_values)\n",
        "                final_bias_dictionary[each_model][each_method][each_community] = roc_output_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e2000d34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2000d34",
        "outputId": "019a3acb-b94c-4a1d-9ce4-dfe9f53b5641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bias Scores (Generalized Mean):\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Calculate generalized mean of bias scores\n",
        "power_value = -5\n",
        "num_communities = len(community_list)\n",
        "\n",
        "print(\"\\nBias Scores (Generalized Mean):\")\n",
        "print(\"=\" * 50)\n",
        "for each_model in final_bias_dictionary:\n",
        "    for each_method in final_bias_dictionary[each_model]:\n",
        "        temp_value = []\n",
        "        for each_community in final_bias_dictionary[each_model][each_method]:\n",
        "            temp_value.append(pow(final_bias_dictionary[each_model][each_method][each_community], power_value))\n",
        "        if len(temp_value) > 0:\n",
        "            score = pow(np.sum(temp_value) / num_communities, 1 / power_value)\n",
        "            print(f\"{each_model} | {each_method}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed22331",
      "metadata": {
        "id": "2ed22331"
      },
      "source": [
        "---\n",
        "\n",
        "# Calculate Explainability\n",
        "\n",
        "Based on: DeYoung et al. (2020) - \"ERASER: A Benchmark to Evaluate Rationalized NLP Models\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "88c76dd4",
      "metadata": {
        "id": "88c76dd4"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import more_itertools as mit\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9e9aa0c6",
      "metadata": {
        "id": "9e9aa0c6"
      },
      "outputs": [],
      "source": [
        "# Import preprocessing utilities\n",
        "from Preprocess.dataCollect import get_annotated_data\n",
        "from Preprocess.spanMatcher import returnMask\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "57ef8972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ef8972",
        "outputId": "9db9e0aa-5842-4875-967d-ccd7c97b7b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 20148 samples for explainability evaluation\n"
          ]
        }
      ],
      "source": [
        "# Load 3-class dataset for explainability\n",
        "dict_data_folder = {\n",
        "    '2': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes_two.npy'},\n",
        "    '3': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "params = {}\n",
        "params['num_classes'] = 3  # hatespeech, offensive, normal\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "data_all_labelled = get_annotated_data(params)\n",
        "print(f\"Loaded {len(data_all_labelled)} samples for explainability evaluation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "eddc527e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eddc527e",
        "outputId": "7a7cc746-354e-49eb-9138-519eff14025b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using standard tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# Configure tokenization parameters\n",
        "params_data = {\n",
        "    'include_special': False,\n",
        "    'bert_tokens': False,  # Set True for BERT models\n",
        "    'type_attention': 'softmax',\n",
        "    'set_decay': 0.1,\n",
        "    'majority': 2,\n",
        "    'max_length': 128,\n",
        "    'variance': 10,\n",
        "    'window': 4,\n",
        "    'alpha': 0.5,\n",
        "    'p_value': 0.8,\n",
        "    'method': 'additive',\n",
        "    'decay': False,\n",
        "    'normalized': False,\n",
        "    'not_recollect': True,\n",
        "}\n",
        "\n",
        "# Initialize tokenizer\n",
        "if params_data['bert_tokens']:\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)\n",
        "else:\n",
        "    print('Using standard tokenizer...')\n",
        "    tokenizer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9ce975f4",
      "metadata": {
        "id": "9ce975f4"
      },
      "outputs": [],
      "source": [
        "def get_training_data(data):\n",
        "    \"\"\"Load dataset and extract token-wise rationales.\"\"\"\n",
        "    final_output = []\n",
        "    print(f'Processing {len(data)} samples...')\n",
        "\n",
        "    for index, row in tqdm(data.iterrows(), total=len(data)):\n",
        "        annotation = row['final_label']\n",
        "        post_id = row['post_id']\n",
        "        annotation_list = [row['label1'], row['label2'], row['label3']]\n",
        "\n",
        "        if annotation != 'undecided':\n",
        "            tokens_all, attention_masks = returnMask(row, params_data, tokenizer)\n",
        "            final_output.append([post_id, annotation, tokens_all, attention_masks, annotation_list])\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "c18b4ce2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "ffca362db10648abb994afb8559bbb09",
            "0058442003cf4ef9a2906ed793ba9642",
            "1613359a683a4d319f42b6d3a9d9dc56",
            "a07ad16b7f984d5194ca0bbfacddc8ac",
            "153df4e924b648cfbcb5afcc4f7efc7a",
            "5e4c436ad192442dbc8ec3166cef613f",
            "679e638931ac4e7598a39499caa36a03",
            "abd0f9e40c1b48ae8af5c0310747b73d",
            "87769220549540d9b967a9d556cc4818",
            "c21f4491622a4f5f9bf89c5ce91e939a",
            "c03ac686ba38499e9c730e3829b74936"
          ]
        },
        "id": "c18b4ce2",
        "outputId": "57d9b6e1-78fe-400a-f04c-718b97f399ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 20148 samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffca362db10648abb994afb8559bbb09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19229 valid samples\n"
          ]
        }
      ],
      "source": [
        "# Process training data\n",
        "training_data = get_training_data(data_all_labelled)\n",
        "print(f\"Processed {len(training_data)} valid samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "71bb9b84",
      "metadata": {
        "id": "71bb9b84"
      },
      "outputs": [],
      "source": [
        "def find_ranges(iterable):\n",
        "    \"\"\"Yield ranges of consecutive numbers.\"\"\"\n",
        "    for group in mit.consecutive_groups(iterable):\n",
        "        group = list(group)\n",
        "        if len(group) == 1:\n",
        "            yield group[0]\n",
        "        else:\n",
        "            yield group[0], group[-1]\n",
        "\n",
        "\n",
        "def get_evidence(post_id, anno_text, explanations):\n",
        "    \"\"\"Convert explanations to ERASER evidence format.\"\"\"\n",
        "    output = []\n",
        "    indexes = sorted([i for i, each in enumerate(explanations) if each == 1])\n",
        "    span_list = list(find_ranges(indexes))\n",
        "\n",
        "    for each in span_list:\n",
        "        if isinstance(each, int):\n",
        "            start, end = each, each + 1\n",
        "        elif len(each) == 2:\n",
        "            start, end = each[0], each[1] + 1\n",
        "        else:\n",
        "            print('Error in span processing')\n",
        "            continue\n",
        "\n",
        "        output.append({\n",
        "            \"docid\": post_id,\n",
        "            \"end_sentence\": -1,\n",
        "            \"end_token\": end,\n",
        "            \"start_sentence\": -1,\n",
        "            \"start_token\": start,\n",
        "            \"text\": ' '.join([str(x) for x in anno_text[start:end]])\n",
        "        })\n",
        "    return output\n",
        "\n",
        "\n",
        "def convert_to_eraser_format(dataset, method, save_split, save_path, id_division):\n",
        "    \"\"\"Convert dataset to ERASER benchmark format.\"\"\"\n",
        "    final_output = []\n",
        "\n",
        "    if save_split:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        os.makedirs(os.path.join(save_path, 'docs'), exist_ok=True)\n",
        "        train_fp = open(os.path.join(save_path, 'train.jsonl'), 'w')\n",
        "        val_fp = open(os.path.join(save_path, 'val.jsonl'), 'w')\n",
        "        test_fp = open(os.path.join(save_path, 'test.jsonl'), 'w')\n",
        "\n",
        "    for eachrow in dataset:\n",
        "        post_id = eachrow[0]\n",
        "        post_class = eachrow[1]\n",
        "        anno_text_list = eachrow[2]\n",
        "\n",
        "        if post_class == 'normal':\n",
        "            continue\n",
        "\n",
        "        explanations = [list(each_explain) for each_explain in eachrow[3]]\n",
        "\n",
        "        # Union of explanations from all annotators\n",
        "        if method == 'union':\n",
        "            final_explanation = [int(any(each)) for each in zip(*explanations)]\n",
        "\n",
        "        temp = {\n",
        "            'annotation_id': post_id,\n",
        "            'classification': post_class,\n",
        "            'evidences': [get_evidence(post_id, list(anno_text_list), final_explanation)],\n",
        "            'query': \"What is the class?\",\n",
        "            'query_type': None\n",
        "        }\n",
        "        final_output.append(temp)\n",
        "\n",
        "        if save_split:\n",
        "            # Save document\n",
        "            with open(os.path.join(save_path, 'docs', post_id), 'w') as fp:\n",
        "                fp.write(' '.join([str(x) for x in list(anno_text_list)]))\n",
        "\n",
        "            # Save to appropriate split\n",
        "            if post_id in id_division['train']:\n",
        "                train_fp.write(json.dumps(temp) + '\\n')\n",
        "            elif post_id in id_division['val']:\n",
        "                val_fp.write(json.dumps(temp) + '\\n')\n",
        "            elif post_id in id_division['test']:\n",
        "                test_fp.write(json.dumps(temp) + '\\n')\n",
        "\n",
        "    if save_split:\n",
        "        train_fp.close()\n",
        "        val_fp.close()\n",
        "        test_fp.close()\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0e8013a1",
      "metadata": {
        "id": "0e8013a1"
      },
      "outputs": [],
      "source": [
        "# Load data splits\n",
        "with open('./Data/post_id_divisions.json') as fp:\n",
        "    id_division = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "80332ce4",
      "metadata": {
        "id": "80332ce4"
      },
      "outputs": [],
      "source": [
        "# Create evaluation directory\n",
        "os.makedirs('./Data/Evaluation/Model_Eval', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5d0e7d11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d0e7d11",
        "outputId": "579c81a0-f0d5-4c9d-874b-20bcbb3e803a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 11415 samples to ERASER format\n"
          ]
        }
      ],
      "source": [
        "# Convert to ERASER format\n",
        "method = 'union'\n",
        "save_split = True\n",
        "save_path = './Data/Evaluation/Model_Eval/'\n",
        "\n",
        "output_eraser = convert_to_eraser_format(training_data, method, save_split, save_path, id_division)\n",
        "print(f\"Converted {len(output_eraser)} samples to ERASER format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0b2f7035",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b2f7035",
        "outputId": "4ebf7b7b-29e5-4ca9-f512-28165628cdce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docs  test.jsonl  train.jsonl  val.jsonl\n"
          ]
        }
      ],
      "source": [
        "# List generated files\n",
        "!ls Data/Evaluation/Model_Eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c70dfea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70dfea6",
        "outputId": "a402a2e2-184e-4379-8a63-bf85572bb349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5185 MainThread Error in instances: 0 instances fail validation: set()\n",
            "  7675 MainThread No sentence level predictions detected, skipping sentence-level diagnostic\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "{'classification_scores': {'accuracy': 0.5779334500875657,\n",
            "                           'aopc_thresholds': None,\n",
            "                           'comprehensiveness': np.float64(0.3071190950170407),\n",
            "                           'comprehensiveness_aopc': None,\n",
            "                           'comprehensiveness_aopc_points': None,\n",
            "                           'comprehensiveness_entropy': np.float64(0.16702580912683954),\n",
            "                           'comprehensiveness_kl': np.float64(0.8087778324712184),\n",
            "                           'prf': {'accuracy': 0.5779334500875657,\n",
            "                                   'hatespeech': {'f1-score': 0.7516525023607177,\n",
            "                                                  'precision': 0.8559139784946237,\n",
            "                                                  'recall': 0.67003367003367,\n",
            "                                                  'support': 594.0},\n",
            "                                   'macro avg': {'f1-score': 0.4420713019564966,\n",
            "                                                 'precision': 0.5252313994249479,\n",
            "                                                 'recall': 0.38271195327156393,\n",
            "                                                 'support': 1142.0},\n",
            "                                   'normal': {'f1-score': 0.0,\n",
            "                                              'precision': 0.0,\n",
            "                                              'recall': 0.0,\n",
            "                                              'support': 0.0},\n",
            "                                   'offensive': {'f1-score': 0.5745614035087719,\n",
            "                                                 'precision': 0.7197802197802198,\n",
            "                                                 'recall': 0.4781021897810219,\n",
            "                                                 'support': 548.0},\n",
            "                                   'weighted avg': {'f1-score': 0.6666735862741447,\n",
            "                                                    'precision': 0.7905888473427031,\n",
            "                                                    'recall': 0.5779334500875657,\n",
            "                                                    'support': 1142.0}},\n",
            "                           'sufficiency': np.float64(0.043159904207988604),\n",
            "                           'sufficiency_aopc': None,\n",
            "                           'sufficiency_aopc_points': None,\n",
            "                           'sufficiency_entropy': np.float64(0.012302636693536505),\n",
            "                           'sufficiency_kl': np.float64(0.082762051427988)},\n",
            " 'iou_scores': [{'macro': {'f1': 0.2223972913201478,\n",
            "                           'p': 0.14403093987157037,\n",
            "                           'r': 0.48781377699941625},\n",
            "                 'micro': {'f1': 0.2202906424011951,\n",
            "                           'p': 0.14318502824858756,\n",
            "                           'r': 0.47733961153619775},\n",
            "                 'threshold': 0.5}],\n",
            " 'rationale_prf': {'instance_macro': {'f1': 0.11444852578828062,\n",
            "                                      'p': 0.07710157618213662,\n",
            "                                      'r': 0.2609311150029189},\n",
            "                   'instance_micro': {'f1': 0.11815835936438952,\n",
            "                                      'p': 0.07680084745762712,\n",
            "                                      'r': 0.25603296056503827}},\n",
            " 'token_prf': {'instance_macro': {'f1': 0.503974763156197,\n",
            "                                  'p': 0.6192498540572097,\n",
            "                                  'r': 0.6368745027505276},\n",
            "               'instance_micro': {'f1': 0.4430827542640556,\n",
            "                                  'p': 0.6191737288135594,\n",
            "                                  'r': 0.3449734408813693}},\n",
            " 'token_soft_metrics': {'auprc': np.float64(0.8412134937433974),\n",
            "                        'average_precision': np.float64(0.8360175423997078),\n",
            "                        'roc_auc_score': np.float64(0.8547483501545116)}}\n"
          ]
        }
      ],
      "source": [
        "# Run ERASER metrics\n",
        "explanation_file = './explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json'\n",
        "if os.path.exists(explanation_file):\n",
        "    !cd eraserbenchmark && PYTHONPATH=./:$PYTHONPATH python rationale_benchmark/metrics.py \\\n",
        "        --split test \\\n",
        "        --data_dir ../Data/Evaluation/Model_Eval \\\n",
        "        --results ../explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json \\\n",
        "        --score_file ../model_explain_output.json\n",
        "else:\n",
        "    print(f\"Explanation file not found: {explanation_file}\")\n",
        "    print(\"Run testing_with_rational.py first.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD0wdMPeV0d9",
        "outputId": "ea1be7b3-e85c-45b4-b7f6-789223863b94"
      },
      "id": "kD0wdMPeV0d9",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate explanations for ERASER evaluation\n",
        "!python testing_with_rational.py birnn_scrat 100\n",
        "\n",
        "# Verify the explanation file was created\n",
        "!ls -la explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMbviCwSab6E",
        "outputId": "71400543-a8a3-4978-9624-f9dff0a130cb"
      },
      "id": "YMbviCwSab6E",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-01 18:25:36.604033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769970336.631386   13022 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769970336.639654   13022 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769970336.670541   13022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970336.670567   13022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970336.670573   13022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769970336.670576   13022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n",
            "total_data 1142\n",
            "100% 1142/1142 [00:01<00:00, 718.10it/s]\n",
            "100% 1142/1142 [00:00<00:00, 21420.85it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:00<00:00, 80.83it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " Accuracy: 0.578\n",
            " Fscore: 0.442\n",
            " Precision: 0.525\n",
            " Recall: 0.383\n",
            " Test took: 0:00:00\n",
            "100% 1142/1142 [00:00<00:00, 9537.69it/s]\n",
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n",
            "100% 1142/1142 [00:00<00:00, 16261.63it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:00<00:00, 388.56it/s]\n",
            "100% 1142/1142 [00:00<00:00, 4470.23it/s]\n",
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n",
            "100% 1142/1142 [00:00<00:00, 15110.99it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:00<00:00, 404.43it/s]\n",
            "\u001b[0m-rw-r--r-- 1 root root 1473974 Feb  1 18:26 explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e2923617",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2923617",
        "outputId": "02ca6583-b82e-4b7d-89a7-6eacc80bc70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EXPLAINABILITY RESULTS\n",
            "==================================================\n",
            "\n",
            "Plausibility:\n",
            "  IOU F1:   0.2224\n",
            "  Token F1: 0.5040\n",
            "  AUPRC:    0.8412\n",
            "\n",
            "Faithfulness:\n",
            "  Comprehensiveness: 0.3071\n",
            "  Sufficiency:       0.0432\n"
          ]
        }
      ],
      "source": [
        "# Print explainability results\n",
        "output_file = './model_explain_output.json'\n",
        "if os.path.exists(output_file):\n",
        "    with open(output_file) as fp:\n",
        "        output_data = json.load(fp)\n",
        "\n",
        "    print('\\n' + '=' * 50)\n",
        "    print('EXPLAINABILITY RESULTS')\n",
        "    print('=' * 50)\n",
        "\n",
        "    print('\\nPlausibility:')\n",
        "    print(f\"  IOU F1:   {output_data['iou_scores'][0]['macro']['f1']:.4f}\")\n",
        "    print(f\"  Token F1: {output_data['token_prf']['instance_macro']['f1']:.4f}\")\n",
        "    print(f\"  AUPRC:    {output_data['token_soft_metrics']['auprc']:.4f}\")\n",
        "\n",
        "    print('\\nFaithfulness:')\n",
        "    print(f\"  Comprehensiveness: {output_data['classification_scores']['comprehensiveness']:.4f}\")\n",
        "    print(f\"  Sufficiency:       {output_data['classification_scores']['sufficiency']:.4f}\")\n",
        "else:\n",
        "    print(f\"Output file not found: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a912fa",
      "metadata": {
        "id": "98a912fa"
      },
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. **Model Training**: Training BiRNN-SCRAT model for hate speech detection\n",
        "2. **Bias Evaluation**: Computing subgroup, BPSN, and BNSP bias metrics\n",
        "3. **Explainability Evaluation**: Computing plausibility and faithfulness metrics\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6174789e9b6f4abf825aecb7f69ce7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f3c623c36c044e2bc78d4aeb8c06a52",
              "IPY_MODEL_9764470ad7c1406589ba918114b5ee05",
              "IPY_MODEL_8813bce2068342e98a0c7075317c0820"
            ],
            "layout": "IPY_MODEL_5b5c5bb0ce5c4e06a6b4daad2062c220"
          }
        },
        "8f3c623c36c044e2bc78d4aeb8c06a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f8e6fc9be04be68fee2ecf4647c5b5",
            "placeholder": "​",
            "style": "IPY_MODEL_fd49177ebaf2458d94468ec99b5fe6ed",
            "value": "Processing models: 100%"
          }
        },
        "9764470ad7c1406589ba918114b5ee05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a334c19ae64d799719e418eb6bd476",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed08a83f376d4f8e81e88caedd306c62",
            "value": 1
          }
        },
        "8813bce2068342e98a0c7075317c0820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc2841eed00942589f8f99d610cdfd11",
            "placeholder": "​",
            "style": "IPY_MODEL_e996e39e10fb4de9a9248b267c3344be",
            "value": " 1/1 [00:00&lt;00:00, 86.33it/s]"
          }
        },
        "5b5c5bb0ce5c4e06a6b4daad2062c220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f8e6fc9be04be68fee2ecf4647c5b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd49177ebaf2458d94468ec99b5fe6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a334c19ae64d799719e418eb6bd476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed08a83f376d4f8e81e88caedd306c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc2841eed00942589f8f99d610cdfd11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e996e39e10fb4de9a9248b267c3344be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffca362db10648abb994afb8559bbb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0058442003cf4ef9a2906ed793ba9642",
              "IPY_MODEL_1613359a683a4d319f42b6d3a9d9dc56",
              "IPY_MODEL_a07ad16b7f984d5194ca0bbfacddc8ac"
            ],
            "layout": "IPY_MODEL_153df4e924b648cfbcb5afcc4f7efc7a"
          }
        },
        "0058442003cf4ef9a2906ed793ba9642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4c436ad192442dbc8ec3166cef613f",
            "placeholder": "​",
            "style": "IPY_MODEL_679e638931ac4e7598a39499caa36a03",
            "value": "100%"
          }
        },
        "1613359a683a4d319f42b6d3a9d9dc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abd0f9e40c1b48ae8af5c0310747b73d",
            "max": 20148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87769220549540d9b967a9d556cc4818",
            "value": 20148
          }
        },
        "a07ad16b7f984d5194ca0bbfacddc8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21f4491622a4f5f9bf89c5ce91e939a",
            "placeholder": "​",
            "style": "IPY_MODEL_c03ac686ba38499e9c730e3829b74936",
            "value": " 20148/20148 [00:26&lt;00:00, 744.18it/s]"
          }
        },
        "153df4e924b648cfbcb5afcc4f7efc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4c436ad192442dbc8ec3166cef613f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679e638931ac4e7598a39499caa36a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abd0f9e40c1b48ae8af5c0310747b73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87769220549540d9b967a9d556cc4818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21f4491622a4f5f9bf89c5ce91e939a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03ac686ba38499e9c730e3829b74936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}